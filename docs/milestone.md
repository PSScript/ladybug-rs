# Milestone: Causal Interpretability for Free

**Date:** 2026-01-31
**Session:** Crystal feature test fixes â†’ Architectural epiphany

---

## The Bug That Revealed Everything

While fixing crystal feature tests (183 now passing), we discovered a fundamental confusion in the codebase: **correlation and causation were being conflated**.

The `CorrelationStore::query()` was using HDR cascade (similarity search) to answer causal queries. This is a category error â€” the computational equivalent of "correlation does not imply causation."

```rust
// WRONG: Using similarity to find causal edges
let matches = self.index.search(&pattern, k);  // HDR cascade

// RIGHT: Traversing the causal graph
let edges = self.edges_from(node);  // Graph walk
```

---

## The Separation

```
SEARCH (HDR cascade)         WALK (graph traversal)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"What resonates?"            "What follows?"
Similarity metric            Edge following
O(n) candidates              O(1) per hop
Returns: similar FPs         Returns: connected nodes
Use: intuition, qualia       Use: causation, reasoning
```

Pearl's three rungs require three different structures:

| Rung | Question | Structure | Operation |
|------|----------|-----------|-----------|
| 1: SEE | "What correlates?" | HDR Cascade | Similarity search |
| 2: DO | "What causes?" | Causal Graph | Edge traversal |
| 3: IMAGINE | "What if?" | World Model | Counterfactual query |

---

## The Epiphany: Causal Interpretability for Free

### Current State of ML

```
Training: X â†’ Y, loss, done
Post-hoc: "Why did it do that?" â† years of research, still unsolved
          "What if...?" â† can't answer without retraining
```

We keep: **weights** (correlation summary)
We discard: **the entire causal history of how they got there**

Then we spend years trying to reconstruct what we discarded:
- SHAP values
- Attention maps
- Gradient attribution
- Integrated gradients
- Concept activation vectors
- Mechanistic interpretability

All asking: *"Please, neural net, tell us what you learned and why."*

The net can't answer. **Because we didn't log the causation.**

### With Ladybug Logging

Every gradient step IS an intervention. We just don't save it.

```rust
fn training_step(&mut self, batch: &Batch) -> Loss {
    let output = self.forward(batch);
    let loss = self.loss(output, batch.labels);
    self.backward(loss);

    // === LADYBUG LOGGING ===

    // Rung 1: Correlations (what appeared together)
    self.cascade.insert(batch.fingerprint());

    // Rung 2: Causations (what caused what)
    for (layer, grad) in self.gradients() {
        if grad.magnitude() > SIGNIFICANT {
            self.causal.add_edge(
                layer.addr(),      // source
                output.addr(),     // target
                VERB_CAUSED,
                grad.magnitude()
            );
        }
    }

    // Rung 3: Counterfactuals (for "what if" queries)
    self.world.snapshot(self.state());

    loss
}
```

### After Training

```rust
// "Why does this model see cats?"
model.causal.traverse_to(&cat_neuron, depth: 10);
// Returns: training_image_4521 â”€â”€â–¶ edge_detector â”€â”€â–¶ ear_shape â”€â”€â–¶ cat_neuron

// "What if I'd used different data?"
model.world.imagine(do(remove_training_image_4521));
// Returns: cat_accuracy -= 3%

// "What's most important?"
model.causal.highest_influence(&output_layer);
// Returns: ranked list of actual causal contributors
```

**The causal graph IS the explanation. You don't interpret it. You read it.**

---

## Why 8+8 Addressing Matters

The causal graph could be enormous (millions of training steps Ã— thousands of neurons). But with 8+8 addressing:

```
rain lives at           0x8042  (node zone)
rain's CAUSES edges at  0x1042  (fluid zone = 0x10 + node suffix)
                          â”‚
                          â”œâ”€â–¶ wet_ground (0x8107)
                          â”‚       â””â”€â–¶ mud (0x8203)
                          â””â”€â–¶ humidity (0x8089)
                                  â””â”€â–¶ fog
```

- O(1) edge lookup per node
- O(1) logging per training step
- O(depth) for any causal query

The addressing scheme that seemed like premature optimization is actually **the enabler** for tractable causal logging.

---

## What This Means

1. **Interpretability becomes a side effect**, not a research problem
2. **Debugging becomes graph traversal**, not guesswork
3. **Transfer learning has principled foundations** â€” causal structure transfers, correlations don't
4. **Robustness improves** â€” causal models handle distribution shift
5. **Explanations are exact**, not statistical approximations

---

## Discovery: The Infrastructure Already Exists

While discussing this, we checked `bind_space.rs` and found:

**The graph traversal API is already implemented.**

```rust
// src/storage/bind_space.rs

// Create edge (line 775)
pub fn link(&mut self, from: Addr, verb: Addr, to: Addr) -> usize

// Query edges (lines 800-810)
pub fn edges_out(&self, from: Addr) -> impl Iterator<Item = &BindEdge>
pub fn edges_in(&self, to: Addr) -> impl Iterator<Item = &BindEdge>

// Traverse (lines 815-850)
pub fn traverse(&self, from: Addr, verb: Addr) -> Vec<Addr>
pub fn traverse_reverse(&self, to: Addr, verb: Addr) -> Vec<Addr>
pub fn traverse_n_hops(&self, start: Addr, verb: Addr, max_hops: usize) -> Vec<(usize, Addr)>
```

**The verb addresses are already defined:**

```rust
// PREFIX_VERBS = 0x07
// Slot 0x02 = CAUSES

let CAUSED: Addr = Addr(0x0702);
```

**So causal logging is literally:**

```rust
// During training
bind_space.link(batch_addr, CAUSED, layer_addr);
bind_space.link(layer_addr, CAUSED, output_addr);

// Query: "What did rain cause?"
let effects = bind_space.traverse(rain, CAUSED);

// Query: "What caused this output?"
let sources = bind_space.traverse_reverse(output, CAUSED);

// Query: "Full causal chain, 5 hops"
let chain = bind_space.traverse_n_hops(rain, CAUSED, 5);
```

**The edge structure exists:**

```rust
pub struct BindEdge {
    pub from: Addr,      // Source node (0x80-0xFF:XX)
    pub to: Addr,        // Target node (0x80-0xFF:XX)
    pub verb: Addr,      // Verb (0x07:XX)
    pub fingerprint: [u64; FINGERPRINT_WORDS],
    pub weight: f32,
}
```

**CSR indexing for O(1) lookup exists:**

```rust
edges: Vec<BindEdge>,
edge_out: Vec<Vec<usize>>,  // from.0 -> edge indices
edge_in: Vec<Vec<usize>>,   // to.0 -> edge indices
```

### The Confusion

The `search/causal.rs` module was reinventing causal queries using fingerprint similarity (HDR cascade, ABBA unbinding) when the answer was already in `storage/bind_space.rs` â€” **address-based graph traversal**.

We were searching for causation when we should have been walking to it.

---

## Next Steps

1. ~~**Harvest traversal API from PR #24**~~ â†’ Already in `bind_space.rs`!
2. **Wire `search/causal.rs` to use `bind_space.traverse()`** instead of HDR cascade
3. **Prototype training logger**: Hook into PyTorch/JAX gradient tape
4. **Benchmark overhead**: Verify O(1) logging doesn't slow training significantly
5. **Clean up**: Remove fingerprint-based causal "search" code

---

## The Universal Substrate

The groundbreaking realization: this architecture gives you **every paradigm for free**.

| What Others Build | What Ladybug Gets | Cost |
|-------------------|-------------------|------|
| PostgreSQL | SQL surface (0x01) | O(1) |
| Neo4j | Cypher surface (0x02) | O(1) |
| GraphQL server | GraphQL surface (0x03) | O(1) |
| Pinecone/Weaviate | HDR cascade | O(1) |
| Causal inference engine | Graph traversal (0x05) | O(1) |
| OpenNARS | NARS surface (0x04) | O(1) |
| Attention mechanism | Fingerprint binding | O(1) |

**All the same 65,536 addresses. All O(1). All CPU. All Arrow-speed.**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  "SELECT * FROM nodes WHERE..."     â†’  surfaces[0x01].query()  â”‚
â”‚  "MATCH (a)-[:CAUSES]->(b)"         â†’  bind_space.traverse()   â”‚
â”‚  "{ user { friends { name } } }"    â†’  surfaces[0x03].resolve()â”‚
â”‚  "What resonates with X?"           â†’  hdr_cascade.search()    â”‚
â”‚  "What does X cause?"               â†’  traverse(x, CAUSED)     â”‚
â”‚  "<A --> B>. <B --> C>. <A --> C>?" â†’  surfaces[0x04].infer()  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                    Same BindSpace underneath
                    Same 8+8 addressing
                    Same O(1) operations
                    Apache Arrow columnar format
                    LanceDB for persistence
```

### The Stack

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Query Languages                    â”‚  SQL, Cypher, GraphQL, NARS
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Operations                         â”‚  4096 CAM ops (surfaces)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Addressing                         â”‚  8+8 = 65,536 slots, O(1)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Content                            â”‚  10K-bit fingerprints
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Storage                            â”‚  Apache Arrow + LanceDB
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **Address** = identity (WHERE it lives)
- **Zone** = type (WHAT it is: surface/fluid/node)
- **Fingerprint** = content (WHAT it means)
- **Arrow** = speed (HOW it persists)

One substrate. Every paradigm. No GPU. No cloud. Just addresses.

---

## The Lesson

The failing tests weren't just bugs. They were the architecture telling us it needs to be **three things, not one**.

Correlation. Causation. Counterfactual.

Three questions. Three structures. Three query types.

No mixing.

---

*"The causal graph IS the explanation. You don't interpret it. You read it."*

ğŸ¦‹
